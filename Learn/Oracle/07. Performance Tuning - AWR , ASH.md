# Oracle AWR and ASH: Complete Learning Guide

---

# Introduction

Oracle Database performance tuning is a critical skill for database administrators and developers. Two of the most powerful tools in Oracle's performance monitoring arsenal are the Automatic Workload Repository (AWR) and Active Session History (ASH). This comprehensive guide will take you from beginner to professional level understanding of these essential performance tuning tools.

# Prerequisites

Before diving into AWR and ASH, ensure you have:
- Basic understanding of Oracle Database architecture
- Knowledge of SQL and PL/SQL
- Understanding of database performance concepts
- Access to Oracle Database 10g or later
- Oracle Diagnostic Pack license (for AWR/ASH features)

# Oracle Performance Monitoring Fundamentals

## Database Performance Metrics

### Key Performance Indicators (KPIs)
- **Response Time**: Time taken to complete user requests
- **Throughput**: Number of transactions processed per unit time
- **Resource Utilization**: CPU, Memory, I/O usage
- **Concurrency**: Number of simultaneous users/sessions

### Oracle Time Model
Oracle uses a hierarchical time model to track where database time is spent:
- **DB Time**: Total time spent in database calls
- **DB CPU**: Time spent using CPU
- **Wait Time**: Time spent waiting for resources

## Performance Tuning Methodology

1. **Identify the Problem**: Define performance issues clearly
2. **Collect Data**: Gather performance statistics
3. **Analyze Data**: Identify bottlenecks and root causes
4. **Implement Solutions**: Apply appropriate tuning techniques
5. **Monitor Results**: Verify improvements and prevent regressions

---

# Chapter 12: Automatic Workload Repository (AWR)

## 12.1 Introduction to AWR

The Automatic Workload Repository (AWR) is Oracle's built-in performance monitoring and analysis tool, collecting, processing, and maintaining performance statistics for problem detection and self-tuning purposes. AWR provides a comprehensive view of database performance over time, making it essential for both reactive troubleshooting and proactive performance management.

### What is AWR?
AWR is a repository of historical performance data that includes:
- Database and instance statistics
- Object statistics
- Performance metrics
- Configuration parameters
- Resource utilization data

### Key Benefits of AWR
- **Historical Analysis**: Compare current performance with historical baselines
- **Trend Analysis**: Identify performance patterns over time
- **Capacity Planning**: Forecast future resource requirements
- **Problem Diagnosis**: Identify performance bottlenecks and their root causes
- **Automated Collection**: Minimal overhead with automatic data collection

## 12.2 AWR Architecture and Components

### AWR Data Collection Process

1. **Snapshot Collection**: AWR automatically takes periodic snapshots of performance data
2. **Data Storage**: Snapshots are stored in the SYSAUX tablespace
3. **Data Retention**: Historical data is maintained based on retention policies
4. **Report Generation**: Data is formatted into comprehensive reports

### AWR Components

#### System Global Area (SGA) Components
- **Shared Pool**: Stores AWR metadata and cursors
- **Buffer Cache**: May impact AWR data collection performance
- **Large Pool**: Used for parallel query operations in AWR

#### Background Processes
- **MMON (Manageability Monitor)**: Main AWR coordinator process
- **MMNL (Manageability Monitor Light)**: Flushes ASH data to disk
- **SMCO (Space Management Coordinator)**: Manages AWR space usage

#### Data Dictionary Views
- **DBA_HIST_** views: Historical performance data
- **V$** views: Current instance statistics
- **GV$** views: Global views for RAC environments

### AWR Data Collection Levels

Oracle provides different levels of AWR statistics collection:

**STATISTICS_LEVEL Parameter Values:**
- **BASIC**: Minimal statistics collection (not recommended)
- **TYPICAL**: Standard collection level (default)
- **ALL**: Maximum statistics collection

```sql
-- Check current statistics level
SELECT value FROM v$parameter WHERE name = 'statistics_level';

-- Change statistics level (requires restart)
ALTER SYSTEM SET statistics_level = 'ALL' SCOPE=SPFILE;
```

## 12.3 AWR Configuration and Management

### AWR Snapshot Configuration

#### Viewing Current AWR Settings
```sql
-- Check AWR configuration
SELECT snap_interval, retention, topnsql 
FROM dba_hist_wr_control;

-- View snapshot history
SELECT snap_id, begin_interval_time, end_interval_time,
       startup_time, instance_number
FROM dba_hist_snapshot
ORDER BY snap_id DESC;
```

#### Modifying AWR Settings
```sql
-- Change snapshot interval and retention
BEGIN
    DBMS_WORKLOAD_REPOSITORY.MODIFY_SNAPSHOT_SETTINGS(
        interval => 30,          -- 30 minutes
        retention => 10080       -- 7 days (in minutes)
    );
END;
/

-- Create manual snapshot
BEGIN
    DBMS_WORKLOAD_REPOSITORY.CREATE_SNAPSHOT();
END;
/
```

### AWR Snapshot Management

#### Best Practices for Snapshot Intervals
- **High-Transaction Systems**: 15-30 minutes
- **Batch Processing Systems**: 60 minutes
- **Development Systems**: 60 minutes or longer
- **Critical Production Systems**: 15 minutes during peak hours

#### Managing AWR Space
```sql
-- Check AWR space usage
SELECT occupant_name, space_usage_kbytes
FROM v$sysaux_occupants
WHERE occupant_name = 'SM/AWR';

-- Purge old snapshots
BEGIN
    DBMS_WORKLOAD_REPOSITORY.DROP_SNAPSHOT_RANGE(
        low_snap_id => 100,
        high_snap_id => 200
    );
END;
/
```

## 12.4 Generating AWR Reports

### Types of AWR Reports

#### 1. AWR Report (awrrpt.sql)
- Standard single-instance report
- Compares two snapshots
- Provides comprehensive performance analysis

#### 2. AWR Compare Period Report (awrddrpt.sql)
- Compares two different time periods
- Useful for before/after analysis
- Helps identify performance regressions

#### 3. AWR Global Report (awrgrpt.sql)
- RAC-specific report
- Provides cluster-wide performance view
- Includes all instances in RAC environment

### Generating AWR Reports

#### Using SQL*Plus Scripts
```sql
-- Generate standard AWR report
@$ORACLE_HOME/rdbms/admin/awrrpt.sql

-- Generate AWR compare report
@$ORACLE_HOME/rdbms/admin/awrddrpt.sql

-- Generate AWR global report (RAC)
@$ORACLE_HOME/rdbms/admin/awrgrpt.sql
```

#### Using DBMS_WORKLOAD_REPOSITORY Package
```sql
-- Generate AWR report using PL/SQL
DECLARE
    l_report CLOB;
BEGIN
    l_report := DBMS_WORKLOAD_REPOSITORY.AWR_REPORT_TEXT(
        l_dbid => 123456789,
        l_inst_num => 1,
        l_bid => 1000,
        l_eid => 1001
    );
    
    -- Output or save the report
    DBMS_OUTPUT.PUT_LINE(l_report);
END;
/
```

#### Report Format Options
- **HTML**: Rich formatting with navigation
- **TEXT**: Plain text for automated processing
- **XML**: Structured data for custom analysis

## 12.5 AWR Report Analysis - Beginner Level

### Understanding AWR Report Structure

#### Report Header Section
The AWR report begins with essential database information:

**Key Metrics to Review:**
- **DB Time**: Total time spent in database calls
- **Elapsed Time**: Wall-clock time for the snapshot period
- **CPUs**: Number of CPUs available to the instance
- **Startup Time**: When the database was last started

**Time Units Used in AWR:**
- **s**: second
- **cs**: centisecond (1/100th of a second)
- **ms**: millisecond (1/1000th of a second)
- **us**: microsecond (1/1000000th of a second)

#### Load Profile Section
The load profile shows average per-second and per-transaction metrics:

**Critical Metrics:**
- **DB Time (s)**: Average active sessions = DB Time / Elapsed Time
- **DB CPU (s)**: CPU time consumed by user processes
- **Logical Reads**: Buffer cache reads (consistent gets + db block gets)
- **Physical Reads**: Disk reads when data not in buffer cache
- **Hard Parses**: SQL statements requiring complete parsing
- **Soft Parses**: SQL statements reusing existing parse trees

**Analysis Tips:**
- High hard parse ratio (>2-3%) indicates bind variable issues
- Physical reads should be minimized through proper indexing
- Redo size indicates DML activity volume

#### Instance Efficiency Percentages
Key efficiency ratios to monitor:

**Buffer Hit %**: Should be >90% for OLTP systems
```
Buffer Hit % = (Logical Reads - Physical Reads) / Logical Reads * 100
```

**Soft Parse %**: Should be >95%
```
Soft Parse % = (Parses - Hard Parses) / Parses * 100
```

**Execute to Parse %**: Should be >90%
```
Execute to Parse % = (Executes - Parses) / Executes * 100
```

### Top Wait Events Analysis

#### Understanding Wait Events
Wait events indicate where the database is spending time when not using CPU:

**Common Wait Event Categories:**
- **Application**: Locks, user I/O waits
- **Concurrency**: Buffer busy waits, latch free
- **System I/O**: db file sequential read, db file scattered read
- **User I/O**: Direct path reads/writes
- **Network**: SQL*Net waits

#### Key Wait Events to Monitor

**db file sequential read**
- Indicates single-block I/O operations
- Usually from index range scans
- Average I/O response time should be <10ms for good performance

**db file scattered read**
- Indicates multi-block I/O operations
- Usually from full table scans
- May indicate missing or inefficient indexes

**log file sync**
- Commit processing wait
- Should average <10ms for good performance
- High waits may indicate I/O bottlenecks

### Host CPU and Instance CPU Analysis

#### Host CPU Section
- **CPUs**: Total number of CPU threads
- **Load Average**: System load compared to CPU count
- **%Idle**: Percentage of CPU time idle

#### Instance CPU Section
- **%Total CPU**: Database's share of total CPU
- **%Busy CPU**: Database CPU utilization
- **%DB CPU**: User process CPU time

**Analysis Guidelines:**
- If %Idle is low and %Total CPU is high: CPU bottleneck
- If %Idle is high but DB CPU is top wait event: Inefficient SQL

## 12.6 AWR Report Analysis - Intermediate Level

### SQL Statistics Analysis

#### SQL Ordered by Elapsed Time
Identifies the most time-consuming SQL statements:

**Key Columns:**
- **Elapsed Time (s)**: Total execution time
- **Executions**: Number of times executed
- **Elapsed per Exec (s)**: Average execution time
- **%Total**: Percentage of total DB time

**Analysis Approach:**
1. Focus on SQL with high total elapsed time
2. Look for SQL with few executions but high elapsed time per execution
3. Consider both high-frequency and long-running queries

#### SQL Ordered by CPU Time
Shows SQL consuming the most CPU resources:

**Analysis Tips:**
- High CPU time with low logical reads: CPU-intensive operations
- High CPU time with high logical reads: Inefficient data access patterns
- Compare with elapsed time to identify CPU vs. wait time issues

#### SQL Ordered by Gets (Logical Reads)
Identifies SQL performing the most logical I/O:

**Key Metrics:**
- **Buffer Gets**: Total logical reads
- **Gets per Exec**: Logical reads per execution
- **%Total**: Percentage of total logical reads

**Optimization Opportunities:**
- High gets per execution indicates inefficient access patterns
- Missing or inappropriate indexes
- Need for SQL tuning or rewriting

#### SQL Ordered by Physical Reads
Shows SQL performing the most disk I/O:

**Analysis Focus:**
- High physical reads may indicate:
  - Missing indexes causing full table scans
  - Insufficient buffer cache
  - Large data set processing

### Segment Statistics Analysis

#### Segments by Logical Reads
Identifies the most frequently accessed database objects:

**Use Cases:**
- Identify hot tables and indexes
- Plan for partitioning strategies
- Optimize frequently accessed objects

#### Segments by Physical Reads
Shows objects causing the most disk I/O:

**Analysis Approach:**
- High physical reads on specific segments may indicate missing indexes or inefficient SQL
- Compare with SQL statistics to correlate object access patterns
- Consider buffer cache sizing for frequently accessed objects

### Wait Event Analysis Deep Dive

#### Buffer Busy Waits
Indicates contention for specific buffer blocks:

**Common Causes:**
- Hot blocks in frequently accessed tables
- Insufficient freelists in table definitions
- High-concurrency applications accessing same data

**Resolution Strategies:**
- Increase freelists and freelist groups
- Consider table partitioning
- Review application design for hot spots

#### Latch Contention
Shows contention for internal Oracle structures:

**Key Latches to Monitor:**
- **Shared pool latch**: Indicates parsing issues
- **Cache buffers chains**: Buffer cache contention
- **Library cache**: Shared pool sizing issues

### Time Model Statistics

#### Understanding Time Breakdown
Time model statistics show where database time is consumed:

**Key Statistics:**
- **sql execute elapsed time**: Time spent executing SQL
- **parse time elapsed**: Time spent parsing SQL
- **hard parse elapsed time**: Time spent on hard parsing
- **PL/SQL execution elapsed time**: Time in PL/SQL code

## 12.7 AWR Report Analysis - Advanced Level

### Advanced Performance Analysis Techniques

#### Database Time Analysis
Understanding the relationship between different time components:

```sql
-- Query to analyze time model statistics
SELECT stat_name,
       value / 1000000 AS seconds,
       ROUND(value / SUM(value) OVER () * 100, 2) AS pct_total
FROM v$sys_time_model
WHERE value > 0
ORDER BY value DESC;
```

#### Workload Characterization
Classify your workload based on AWR metrics:

**OLTP Characteristics:**
- High user calls per second
- Low rows per execution
- High parse-to-execute ratio
- Short elapsed times per SQL

**Batch/DW Characteristics:**
- Low user calls per second
- High rows per execution
- Low parse-to-execute ratio
- Long elapsed times per SQL

### Advanced SQL Analysis

#### Version Count Analysis
Identify SQL with multiple child cursors:

```sql
-- Find SQL with high version counts
SELECT sql_id,
       COUNT(*) AS version_count,
       MIN(plan_hash_value) AS min_plan_hash,
       MAX(plan_hash_value) AS max_plan_hash
FROM v$sql
GROUP BY sql_id
HAVING COUNT(*) > 10
ORDER BY version_count DESC;
```

#### Plan Instability Detection
Identify SQL with changing execution plans:

**Indicators:**
- Multiple plan hash values for same SQL_ID
- Varying execution statistics between snapshots
- Different resource consumption patterns

### Memory Analysis

#### SGA Target Advisory
Analyze the effectiveness of SGA sizing:

**Key Metrics:**
- **Size Factor**: Relative size compared to current
- **Est DB Time**: Estimated database time with different sizes
- **Est Physical Reads**: Projected I/O with size changes

#### PGA Target Advisory
Optimize Program Global Area sizing:

**Analysis Points:**
- **Estd PGA Overalloc Count**: Should be 0
- **Estd Extra Bytes Read**: Additional I/O due to PGA constraints
- **Estd PGA Cache Hit %**: Effectiveness of PGA memory

### Advanced Wait Event Analysis

#### Enqueue Analysis
Detailed analysis of locking and resource contention:

**Common Enqueues:**
- **TX**: Transaction locks (row-level locking)
- **TM**: DML locks (table-level locking)
- **UL**: User-defined locks

#### I/O Analysis
Comprehensive analysis of I/O patterns:

**File I/O Statistics:**
- Identify hot files and tablespaces
- Analyze read/write patterns
- Optimize storage layout

**Tablespace I/O Stats:**
- **Av Rd(ms)**: Average read time (<10ms ideal)
- **Av Buf Wt(ms)**: Average buffer wait time
- **Buffer Hit%**: Tablespace-level cache efficiency

## 12.8 AWR Data Mining and Custom Queries

### Accessing AWR Data Directly

#### Key AWR Views
```sql
-- Historical snapshots
SELECT * FROM dba_hist_snapshot;

-- System statistics
SELECT * FROM dba_hist_sysstat;

-- Wait events
SELECT * FROM dba_hist_system_event;

-- SQL statistics
SELECT * FROM dba_hist_sqlstat;

-- Active Session History
SELECT * FROM dba_hist_active_sess_history;
```

### Custom AWR Analysis Queries

#### Top SQL by Resource Consumption
```sql
-- Top SQL by elapsed time over last 7 days
WITH sql_stats AS (
    SELECT sql_id,
           SUM(elapsed_time_delta) / 1000000 AS elapsed_seconds,
           SUM(executions_delta) AS total_executions,
           SUM(buffer_gets_delta) AS total_gets
    FROM dba_hist_sqlstat s
    JOIN dba_hist_snapshot sn USING (snap_id, dbid, instance_number)
    WHERE sn.begin_interval_time >= SYSDATE - 7
    GROUP BY sql_id
)
SELECT sql_id,
       elapsed_seconds,
       total_executions,
       ROUND(elapsed_seconds / NULLIF(total_executions, 0), 3) AS avg_elapsed,
       total_gets
FROM sql_stats
WHERE elapsed_seconds > 0
ORDER BY elapsed_seconds DESC
FETCH FIRST 10 ROWS ONLY;
```

#### Historical Performance Trends
```sql
-- Daily performance trends
SELECT TRUNC(begin_interval_time) AS day,
       AVG(db_time) / 1000000 AS avg_db_time_seconds,
       AVG(cpu_time) / 1000000 AS avg_cpu_seconds,
       COUNT(*) AS snapshot_count
FROM (
    SELECT s.begin_interval_time,
           st.value AS db_time,
           LAG(st.value) OVER (ORDER BY s.snap_id) AS prev_db_time,
           cpu.value AS cpu_time,
           LAG(cpu.value) OVER (ORDER BY s.snap_id) AS prev_cpu_time
    FROM dba_hist_snapshot s
    JOIN dba_hist_sys_time_model st ON (s.snap_id = st.snap_id 
                                       AND s.dbid = st.dbid 
                                       AND s.instance_number = st.instance_number)
    JOIN dba_hist_sys_time_model cpu ON (s.snap_id = cpu.snap_id 
                                        AND s.dbid = cpu.dbid 
                                        AND s.instance_number = cpu.instance_number)
    WHERE st.stat_name = 'DB time'
      AND cpu.stat_name = 'DB CPU'
      AND s.begin_interval_time >= SYSDATE - 30
) t
WHERE prev_db_time IS NOT NULL
GROUP BY TRUNC(begin_interval_time)
ORDER BY day;
```

### Performance Baseline Creation

#### Creating Performance Baselines
```sql
-- Create a baseline for normal business hours
BEGIN
    DBMS_WORKLOAD_REPOSITORY.CREATE_BASELINE(
        start_snap_id => 1000,
        end_snap_id => 1100,
        baseline_name => 'NORMAL_BUSINESS_HOURS',
        expiration => SYSDATE + 365
    );
END;
/

-- View existing baselines
SELECT baseline_name, start_snap_id, end_snap_id, 
       creation_time, expiration
FROM dba_hist_baseline;
```

## 12.9 AWR Best Practices and Troubleshooting

### AWR Collection Best Practices

#### Optimal Configuration Settings
1. **Statistics Level**: Set to TYPICAL or ALL
2. **Snapshot Interval**: 15-30 minutes for production
3. **Retention Period**: 7-14 days minimum
4. **Manual Snapshots**: Before/after major changes

#### Data Collection Guidelines
- **Multiple Reports**: Compare good vs. bad periods
- **Specific Time Frames**: Focus on problem windows
- **Shorter Intervals**: Break long reports into smaller periods
- **RAC Considerations**: Analyze all instances

### Common AWR Issues and Solutions

#### Issue: Missing or Incomplete Data
**Causes:**
- STATISTICS_LEVEL set to BASIC
- Insufficient SYSAUX tablespace
- AWR retention too short

**Solutions:**
```sql
-- Check statistics level
ALTER SYSTEM SET statistics_level = 'TYPICAL';

-- Increase SYSAUX tablespace
ALTER TABLESPACE sysaux ADD DATAFILE 
  '/path/to/sysaux02.dbf' SIZE 4G AUTOEXTEND ON;

-- Increase retention
BEGIN
    DBMS_WORKLOAD_REPOSITORY.MODIFY_SNAPSHOT_SETTINGS(
        retention => 20160  -- 14 days
    );
END;
/
```

#### Issue: High AWR Collection Overhead
**Symptoms:**
- Performance degradation during snapshot collection
- High MMON process CPU usage
- Long-running AWR queries

**Solutions:**
- Reduce snapshot frequency during peak hours
- Increase SYSAUX tablespace to avoid space pressure
- Monitor AWR-related wait events

### AWR Maintenance Procedures

#### Regular Maintenance Tasks
```sql
-- Clean up old snapshots beyond retention
BEGIN
    DBMS_WORKLOAD_REPOSITORY.PURGE_SNAPSHOT_RANGE(
        low_snap_id => 1,
        high_snap_id => 500
    );
END;
/

-- Check AWR space usage
SELECT occupant_name, 
       space_usage_kbytes / 1024 AS space_usage_mb,
       schema_name
FROM v$sysaux_occupants
WHERE occupant_name LIKE '%AWR%';

-- Monitor MMON performance
SELECT name, time_waited_micro / 1000000 AS seconds_waited
FROM v$system_event
WHERE name LIKE '%MMON%';
```

## 12.10 AWR in RAC Environment

### RAC-Specific Considerations

#### Global vs. Instance-Specific Analysis
- **Global Reports**: Cluster-wide performance view
- **Instance Reports**: Node-specific analysis
- **Cross-Instance Waits**: RAC-specific wait events

#### RAC-Specific Wait Events
- **gc cr request**: Global cache consistent read
- **gc current request**: Global cache current block
- **gc buffer busy**: Global cache buffer busy
- **gcs remote message**: Global cache services messaging
- **ges remote message**: Global enqueue services messaging

### Generating RAC AWR Reports

#### Global AWR Report
```sql
-- Generate global AWR report
@$ORACLE_HOME/rdbms/admin/awrgrpt.sql

-- PL/SQL approach for global report
DECLARE
    l_report CLOB;
BEGIN
    l_report := DBMS_WORKLOAD_REPOSITORY.AWR_GLOBAL_REPORT_TEXT(
        l_dbid => :dbid,
        l_inst_num_list => '1,2,3,4',  -- All instances
        l_bid => :begin_snap,
        l_eid => :end_snap
    );
END;
/
```

#### RAC Load Balancing Analysis
```sql
-- Compare load across RAC instances
SELECT instance_number,
       SUM(executions_delta) AS total_executions,
       SUM(elapsed_time_delta) / 1000000 AS elapsed_seconds,
       COUNT(DISTINCT sql_id) AS unique_sql_count
FROM dba_hist_sqlstat
WHERE snap_id BETWEEN :begin_snap AND :end_snap
GROUP BY instance_number
ORDER BY instance_number;
```

### RAC Performance Optimization

#### Inter-node Communication Optimization
- Monitor gc wait events
- Analyze interconnect performance
- Optimize application partitioning

#### Instance-Specific Tuning
- Balance workload across instances
- Configure services appropriately
- Monitor resource usage by instance

---

# Complete Oracle ASH (Active Session History) Guide: Beginner to Pro

## Table of Contents

1. [Introduction](#introduction)
1. [What is ASH?](#what-is-ash)
1. [Prerequisites](#prerequisites)
1. [ASH Architecture](#ash-architecture)
1. [ASH Views and Tables](#ash-views-and-tables)
1. [Basic ASH Queries](#basic-ash-queries)
1. [Understanding ASH Data](#understanding-ash-data)
1. [Wait Events Analysis](#wait-events-analysis)
1. [SQL Performance Analysis](#sql-performance-analysis)
1. [Session Analysis](#session-analysis)
1. [Time-based Analysis](#time-based-analysis)
1. [Advanced ASH Techniques](#advanced-ash-techniques)
1. [ASH Analytics](#ash-analytics)
1. [ASH with AWR](#ash-with-awr)
1. [Performance Tuning with ASH](#performance-tuning-with-ash)
1. [ASH Reporting](#ash-reporting)
1. [Monitoring and Alerting](#monitoring-and-alerting)
1. [Best Practices](#best-practices)
1. [Troubleshooting Common Issues](#troubleshooting-common-issues)
1. [ASH in Different Oracle Versions](#ash-in-different-oracle-versions)

## Introduction

Oracle Active Session History (ASH) is one of the most powerful performance monitoring and diagnostic tools available in Oracle Database. It provides detailed information about active database sessions, capturing snapshots of session activity every second.

### Why Learn ASH?

- **Real-time Performance Monitoring**: See what’s happening right now
- **Historical Analysis**: Analyze past performance issues
- **Root Cause Analysis**: Drill down to specific problems
- **Proactive Monitoring**: Identify issues before they become critical
- **Comprehensive Coverage**: Covers all database activity

## What is ASH?

Active Session History (ASH) is a built-in Oracle feature that:

- Samples active sessions every second
- Stores session state information in memory (SGA)
- Automatically persists samples to AWR (Automatic Workload Repository)
- Provides rich metadata about database activity
- Enables detailed performance analysis

### Key Benefits

- **Lightweight**: Minimal overhead on database performance
- **Comprehensive**: Captures all types of database activity
- **Flexible**: Multiple ways to query and analyze data
- **Integrated**: Works seamlessly with other Oracle tools

## Prerequisites

### Database Requirements

- Oracle Database 10g or later (ASH introduced in 10g)
- Diagnostic Pack license (for full ASH functionality)
- Sufficient SGA memory allocation

### Knowledge Requirements

- Basic SQL knowledge
- Understanding of Oracle architecture
- Familiarity with wait events
- Basic performance tuning concepts

### Privileges Required

```sql
-- Minimum privileges for ASH access
GRANT SELECT ON V$ACTIVE_SESSION_HISTORY TO username;
GRANT SELECT ON DBA_HIST_ACTIVE_SESS_HISTORY TO username;
GRANT SELECT ON V$SESSION TO username;
GRANT SELECT ON V$SQL TO username;
GRANT SELECT ON V$EVENT_NAME TO username;
```

## ASH Architecture

### Memory Structure

```
SGA (System Global Area)
├── Shared Pool
├── Database Buffer Cache
├── Redo Log Buffer
└── ASH Buffer (Part of SGA)
    ├── Active Session Samples (every 1 second)
    ├── Circular Buffer (1 hour retention)
    └── Background Process (MMON) → AWR
```

### Data Flow

1. **Sampling**: Every second, Oracle samples active sessions
1. **Storage**: Samples stored in circular buffer in SGA
1. **Persistence**: MMON process writes samples to AWR every 10 minutes
1. **Retention**: Memory samples retained for ~1 hour, AWR samples for 8+ days

### Key Components

- **V$ACTIVE_SESSION_HISTORY**: Real-time ASH data (memory)
- **DBA_HIST_ACTIVE_SESS_HISTORY**: Historical ASH data (AWR)
- **ASH Buffer**: In-memory circular buffer
- **MMON Process**: Background process for AWR persistence

## ASH Views and Tables

### Primary ASH Views

#### V$ACTIVE_SESSION_HISTORY

Real-time ASH data from memory (last ~1 hour):

```sql
-- View structure
DESC V$ACTIVE_SESSION_HISTORY;

-- Key columns
SELECT column_name, data_type 
FROM ALL_TAB_COLUMNS 
WHERE table_name = 'V$ACTIVE_SESSION_HISTORY'
AND owner = 'SYS'
ORDER BY column_id;
```

#### DBA_HIST_ACTIVE_SESS_HISTORY

Historical ASH data from AWR:

```sql
-- View structure
DESC DBA_HIST_ACTIVE_SESS_HISTORY;

-- Key differences from V$ASH
-- - Includes DBID, INSTANCE_NUMBER
-- - Includes SNAP_ID for AWR correlation
-- - Longer retention period
```

### Important ASH Columns

#### Time Columns

- **SAMPLE_TIME**: When the sample was taken
- **SAMPLE_ID**: Unique identifier for each sample

#### Session Information

- **SESSION_ID**: Oracle session identifier
- **SESSION_SERIAL#**: Session serial number
- **USER_ID**: Database user ID
- **PROGRAM**: Client program name
- **MACHINE**: Client machine name

#### SQL Information

- **SQL_ID**: Unique SQL identifier
- **SQL_CHILD_NUMBER**: Child cursor number
- **SQL_PLAN_HASH_VALUE**: Execution plan hash
- **SQL_EXEC_ID**: SQL execution identifier

#### Wait Event Information

- **EVENT**: Wait event name
- **EVENT_ID**: Wait event identifier
- **WAIT_CLASS**: Wait event class
- **WAIT_CLASS_ID**: Wait event class ID
- **P1, P2, P3**: Wait event parameters
- **WAIT_TIME**: Wait time in microseconds

#### Resource Information

- **CURRENT_OBJ#**: Current object number
- **CURRENT_FILE#**: Current file number
- **CURRENT_BLOCK#**: Current block number

## Basic ASH Queries

### Current Active Sessions

```sql
-- What's happening right now?
SELECT 
    sample_time,
    session_id,
    session_serial#,
    user_id,
    program,
    event,
    wait_class,
    sql_id
FROM v$active_session_history
WHERE sample_time >= SYSDATE - 5/1440  -- Last 5 minutes
ORDER BY sample_time DESC;
```

### Top Wait Events

```sql
-- Top wait events in last hour
SELECT 
    event,
    wait_class,
    COUNT(*) as sample_count,
    ROUND(COUNT(*) * 100 / SUM(COUNT(*)) OVER (), 2) as pct_total
FROM v$active_session_history
WHERE sample_time >= SYSDATE - 1/24  -- Last 1 hour
AND event IS NOT NULL
GROUP BY event, wait_class
ORDER BY sample_count DESC;
```

### Top SQL Statements

```sql
-- Top SQL by activity
SELECT 
    sql_id,
    COUNT(*) as sample_count,
    ROUND(COUNT(*) * 100 / SUM(COUNT(*)) OVER (), 2) as pct_total,
    MIN(sample_time) as first_seen,
    MAX(sample_time) as last_seen
FROM v$active_session_history
WHERE sample_time >= SYSDATE - 1/24  -- Last 1 hour
AND sql_id IS NOT NULL
GROUP BY sql_id
ORDER BY sample_count DESC;
```

### Session Activity Timeline

```sql
-- Activity timeline for specific session
SELECT 
    sample_time,
    event,
    wait_class,
    sql_id,
    current_obj#,
    p1text,
    p1,
    p2text,
    p2
FROM v$active_session_history
WHERE session_id = &session_id
AND session_serial# = &session_serial
AND sample_time >= SYSDATE - 1/24
ORDER BY sample_time;
```

## Understanding ASH Data

### Sample Frequency and Coverage

ASH samples active sessions every second, but:

- Only **active** sessions are sampled
- Sessions waiting on idle events are not included
- CPU-bound sessions are sampled when on CPU
- Each sample represents ~1 second of database time

### Active Session Definition

A session is considered “active” if it’s:

- Currently executing on CPU
- Waiting for a non-idle event
- Waiting for I/O operations
- Waiting for locks or latches

### Interpreting Sample Counts

```sql
-- Convert samples to time estimates
SELECT 
    event,
    COUNT(*) as samples,
    ROUND(COUNT(*) / 60, 2) as estimated_minutes,
    ROUND(COUNT(*) / 3600, 2) as estimated_hours
FROM v$active_session_history
WHERE sample_time >= SYSDATE - 1
GROUP BY event
ORDER BY samples DESC;
```

## Wait Events Analysis

### Understanding Wait Events

Wait events indicate what a session is waiting for:

#### Major Wait Classes

1. **User I/O**: Disk reads for user queries
1. **System I/O**: System-related I/O operations
1. **Concurrency**: Locking and concurrency waits
1. **Application**: Application-specific waits
1. **Configuration**: Database configuration issues
1. **Administrative**: DBA operations
1. **Network**: Network-related delays
1. **Commit**: Transaction commit processing

### Common Wait Events Analysis

```sql
-- Detailed wait event analysis
SELECT 
    wait_class,
    event,
    COUNT(*) as samples,
    ROUND(AVG(wait_time)/1000, 2) as avg_wait_ms,
    ROUND(MIN(wait_time)/1000, 2) as min_wait_ms,
    ROUND(MAX(wait_time)/1000, 2) as max_wait_ms,
    COUNT(DISTINCT session_id) as unique_sessions
FROM v$active_session_history
WHERE sample_time >= SYSDATE - 1/24
AND event IS NOT NULL
GROUP BY wait_class, event
ORDER BY samples DESC;
```

### I/O Wait Analysis

```sql
-- I/O-related wait events with file information
SELECT 
    event,
    current_file#,
    df.file_name,
    df.tablespace_name,
    COUNT(*) as samples,
    COUNT(DISTINCT current_block#) as unique_blocks
FROM v$active_session_history ash
LEFT JOIN dba_data_files df ON ash.current_file# = df.file_id
WHERE ash.sample_time >= SYSDATE - 1/24
AND ash.wait_class = 'User I/O'
GROUP BY event, current_file#, df.file_name, df.tablespace_name
ORDER BY samples DESC;
```

### Lock Wait Analysis

```sql
-- Lock contention analysis
SELECT 
    ash.event,
    ash.p1 as lock_type,
    ash.p2 as lock_id1,
    ash.p3 as lock_id2,
    COUNT(*) as samples,
    COUNT(DISTINCT ash.session_id) as waiting_sessions,
    MIN(ash.sample_time) as first_occurrence,
    MAX(ash.sample_time) as last_occurrence
FROM v$active_session_history ash
WHERE ash.sample_time >= SYSDATE - 1/24
AND ash.event LIKE '%enq:%'
GROUP BY ash.event, ash.p1, ash.p2, ash.p3
ORDER BY samples DESC;
```

## SQL Performance Analysis

### Top SQL by Database Time

```sql
-- Top SQL statements by total database time
SELECT 
    ash.sql_id,
    s.sql_text,
    COUNT(*) as db_time_seconds,
    ROUND(COUNT(*) * 100 / SUM(COUNT(*)) OVER (), 2) as pct_db_time,
    COUNT(DISTINCT ash.session_id) as unique_sessions,
    ROUND(AVG(ash.wait_time)/1000, 2) as avg_wait_ms
FROM v$active_session_history ash
LEFT JOIN v$sql s ON ash.sql_id = s.sql_id
WHERE ash.sample_time >= SYSDATE - 1/24
AND ash.sql_id IS NOT NULL
GROUP BY ash.sql_id, s.sql_text
ORDER BY db_time_seconds DESC;
```

### SQL Execution Timeline

```sql
-- SQL execution timeline analysis
SELECT 
    sql_id,
    sql_exec_id,
    MIN(sample_time) as exec_start,
    MAX(sample_time) as exec_end,
    COUNT(*) as duration_seconds,
    COUNT(DISTINCT event) as wait_event_count,
    LISTAGG(DISTINCT event, ', ') WITHIN GROUP (ORDER BY event) as wait_events
FROM v$active_session_history
WHERE sample_time >= SYSDATE - 1/24
AND sql_id = '&sql_id'
AND sql_exec_id IS NOT NULL
GROUP BY sql_id, sql_exec_id
ORDER BY exec_start;
```

### SQL Plan Analysis

```sql
-- SQL plan step analysis
SELECT 
    ash.sql_id,
    ash.sql_plan_hash_value,
    ash.sql_plan_line_id,
    p.operation,
    p.options,
    p.object_name,
    COUNT(*) as samples,
    ROUND(COUNT(*) * 100 / SUM(COUNT(*)) OVER (PARTITION BY ash.sql_id), 2) as pct_sql_time
FROM v$active_session_history ash
LEFT JOIN v$sql_plan p ON ash.sql_id = p.sql_id 
    AND ash.sql_plan_hash_value = p.plan_hash_value
    AND ash.sql_plan_line_id = p.id
WHERE ash.sample_time >= SYSDATE - 1/24
AND ash.sql_id = '&sql_id'
GROUP BY ash.sql_id, ash.sql_plan_hash_value, ash.sql_plan_line_id,
         p.operation, p.options, p.object_name
ORDER BY samples DESC;
```

## Session Analysis

### Session Activity Profile

```sql
-- Complete session activity profile
SELECT 
    session_id,
    session_serial#,
    user_id,
    program,
    machine,
    COUNT(*) as total_samples,
    COUNT(CASE WHEN event IS NULL THEN 1 END) as cpu_samples,
    COUNT(CASE WHEN event IS NOT NULL THEN 1 END) as wait_samples,
    COUNT(DISTINCT sql_id) as unique_sqls,
    MIN(sample_time) as first_seen,
    MAX(sample_time) as last_seen
FROM v$active_session_history
WHERE sample_time >= SYSDATE - 1/24
GROUP BY session_id, session_serial#, user_id, program, machine
ORDER BY total_samples DESC;
```

### Session Wait Profile

```sql
-- Session wait event breakdown
SELECT 
    session_id,
    session_serial#,
    wait_class,
    event,
    COUNT(*) as samples,
    ROUND(COUNT(*) * 100 / SUM(COUNT(*)) OVER (PARTITION BY session_id, session_serial#), 2) as pct_session_time
FROM v$active_session_history
WHERE sample_time >= SYSDATE - 1/24
AND session_id = &session_id
AND session_serial# = &session_serial
GROUP BY session_id, session_serial#, wait_class, event
ORDER BY samples DESC;
```

### Blocking Session Analysis

```sql
-- Find blocking sessions
SELECT 
    ash.sample_time,
    ash.session_id as waiting_session,
    ash.blocking_session as blocking_session,
    ash.event,
    ash.p1text,
    ash.p1,
    bs.program as blocking_program,
    bs.sql_id as blocking_sql_id
FROM v$active_session_history ash
LEFT JOIN v$session bs ON ash.blocking_session = bs.sid
WHERE ash.sample_time >= SYSDATE - 1/24
AND ash.blocking_session IS NOT NULL
ORDER BY ash.sample_time DESC;
```

## Time-based Analysis

### Hourly Activity Patterns

```sql
-- Database activity by hour
SELECT 
    EXTRACT(HOUR FROM sample_time) as hour_of_day,
    COUNT(*) as total_samples,
    COUNT(CASE WHEN event IS NULL THEN 1 END) as cpu_samples,
    COUNT(CASE WHEN wait_class = 'User I/O' THEN 1 END) as io_samples,
    COUNT(CASE WHEN wait_class = 'Concurrency' THEN 1 END) as lock_samples,
    COUNT(DISTINCT session_id) as unique_sessions
FROM v$active_session_history
WHERE sample_time >= SYSDATE - 7  -- Last 7 days
GROUP BY EXTRACT(HOUR FROM sample_time)
ORDER BY hour_of_day;
```

### Daily Activity Trends (Using AWR History)

```sql
-- Daily activity trends from AWR
SELECT 
    TRUNC(sample_time) as activity_date,
    COUNT(*) as total_samples,
    COUNT(CASE WHEN event IS NULL THEN 1 END) as cpu_samples,
    ROUND(COUNT(*) / (24 * 3600), 2) as avg_active_sessions,
    COUNT(DISTINCT sql_id) as unique_sqls
FROM dba_hist_active_sess_history
WHERE sample_time >= SYSDATE - 30  -- Last 30 days
GROUP BY TRUNC(sample_time)
ORDER BY activity_date;
```

### Peak Activity Analysis

```sql
-- Find peak activity periods
WITH hourly_activity AS (
    SELECT 
        TRUNC(sample_time, 'HH') as hour,
        COUNT(*) as samples
    FROM v$active_session_history
    WHERE sample_time >= SYSDATE - 7
    GROUP BY TRUNC(sample_time, 'HH')
)
SELECT 
    hour,
    samples,
    RANK() OVER (ORDER BY samples DESC) as activity_rank
FROM hourly_activity
WHERE samples > (SELECT AVG(samples) * 1.5 FROM hourly_activity)
ORDER BY samples DESC;
```

## Advanced ASH Techniques

### ASH Analytics Functions

```sql
-- Using analytical functions with ASH
SELECT 
    sample_time,
    session_id,
    event,
    sql_id,
    -- Running totals
    COUNT(*) OVER (PARTITION BY session_id ORDER BY sample_time) as session_samples,
    -- Time differences
    LAG(sample_time) OVER (PARTITION BY session_id ORDER BY sample_time) as prev_sample,
    sample_time - LAG(sample_time) OVER (PARTITION BY session_id ORDER BY sample_time) as gap,
    -- Event changes
    LAG(event) OVER (PARTITION BY session_id ORDER BY sample_time) as prev_event,
    CASE WHEN event != LAG(event) OVER (PARTITION BY session_id ORDER BY sample_time) 
         THEN 'EVENT_CHANGE' END as event_transition
FROM v$active_session_history
WHERE sample_time >= SYSDATE - 1/24
AND session_id = &session_id
ORDER BY sample_time;
```

### Correlation Analysis

```sql
-- Correlate ASH with system metrics
SELECT 
    TRUNC(ash.sample_time, 'MI') as minute,
    COUNT(*) as ash_samples,
    AVG(s.value) as avg_cpu_usage
FROM v$active_session_history ash
CROSS JOIN v$sysstat s
WHERE ash.sample_time >= SYSDATE - 1/24
AND s.name = 'CPU used by this session'
GROUP BY TRUNC(ash.sample_time, 'MI')
ORDER BY minute;
```

### Custom ASH Aggregations

```sql
-- Custom aggregation: SQL execution phases
WITH sql_phases AS (
    SELECT 
        sql_id,
        sql_exec_id,
        CASE 
            WHEN sql_plan_line_id = 0 THEN 'PARSE'
            WHEN event LIKE 'db file%read' THEN 'IO_READ'
            WHEN event LIKE '%sort%' THEN 'SORT'
            WHEN event IS NULL THEN 'CPU'
            ELSE 'OTHER_WAIT'
        END as execution_phase,
        COUNT(*) as samples
    FROM v$active_session_history
    WHERE sample_time >= SYSDATE - 1/24
    AND sql_id IS NOT NULL
    GROUP BY sql_id, sql_exec_id, 
        CASE 
            WHEN sql_plan_line_id = 0 THEN 'PARSE'
            WHEN event LIKE 'db file%read' THEN 'IO_READ'
            WHEN event LIKE '%sort%' THEN 'SORT'
            WHEN event IS NULL THEN 'CPU'
            ELSE 'OTHER_WAIT'
        END
)
SELECT 
    sql_id,
    execution_phase,
    SUM(samples) as total_samples,
    ROUND(SUM(samples) * 100 / SUM(SUM(samples)) OVER (PARTITION BY sql_id), 2) as pct_sql_time
FROM sql_phases
GROUP BY sql_id, execution_phase
ORDER BY sql_id, total_samples DESC;
```

## ASH Analytics

### Built-in ASH Analytics

Oracle provides several built-in analytical functions for ASH:

#### ASH Report (ashrpt.sql)

```sql
-- Generate ASH report (run from SQL*Plus)
@$ORACLE_HOME/rdbms/admin/ashrpt.sql
```

#### ASH Global Report (ashglbr.sql)

```sql
-- Generate global ASH report for RAC
@$ORACLE_HOME/rdbms/admin/ashglbr.sql
```

### Custom ASH Analytics

#### Top Events by Time Period

```sql
-- Create reusable ASH analytics view
CREATE OR REPLACE VIEW ash_top_events AS
SELECT 
    sample_time,
    wait_class,
    event,
    COUNT(*) OVER (
        PARTITION BY wait_class, event 
        ORDER BY sample_time 
        RANGE BETWEEN INTERVAL '5' MINUTE PRECEDING AND CURRENT ROW
    ) as rolling_5min_count
FROM v$active_session_history
WHERE sample_time >= SYSDATE - 1;
```

#### Session Clustering Analysis

```sql
-- Identify similar session patterns
WITH session_profiles AS (
    SELECT 
        session_id,
        session_serial#,
        program,
        COUNT(*) as total_samples,
        COUNT(CASE WHEN event IS NULL THEN 1 END) as cpu_samples,
        COUNT(CASE WHEN wait_class = 'User I/O' THEN 1 END) as io_samples,
        COUNT(CASE WHEN wait_class = 'Concurrency' THEN 1 END) as lock_samples,
        COUNT(DISTINCT sql_id) as unique_sqls
    FROM v$active_session_history
    WHERE sample_time >= SYSDATE - 1/24
    GROUP BY session_id, session_serial#, program
)
SELECT 
    CASE 
        WHEN cpu_samples > total_samples * 0.7 THEN 'CPU_INTENSIVE'
        WHEN io_samples > total_samples * 0.7 THEN 'IO_INTENSIVE'
        WHEN lock_samples > total_samples * 0.3 THEN 'LOCK_CONTENTION'
        WHEN unique_sqls > 100 THEN 'HIGH_SQL_VARIETY'
        ELSE 'MIXED_WORKLOAD'
    END as session_profile,
    COUNT(*) as session_count,
    AVG(total_samples) as avg_samples
FROM session_profiles
GROUP BY 
    CASE 
        WHEN cpu_samples > total_samples * 0.7 THEN 'CPU_INTENSIVE'
        WHEN io_samples > total_samples * 0.7 THEN 'IO_INTENSIVE'
        WHEN lock_samples > total_samples * 0.3 THEN 'LOCK_CONTENTION'
        WHEN unique_sqls > 100 THEN 'HIGH_SQL_VARIETY'
        ELSE 'MIXED_WORKLOAD'
    END;
```

## ASH with AWR

### Correlating ASH with AWR Snapshots

```sql
-- ASH activity aligned with AWR snapshots
SELECT 
    s.snap_id,
    s.begin_interval_time,
    s.end_interval_time,
    COUNT(ash.sample_id) as ash_samples,
    COUNT(DISTINCT ash.session_id) as unique_sessions,
    COUNT(DISTINCT ash.sql_id) as unique_sqls
FROM dba_hist_snapshot s
LEFT JOIN dba_hist_active_sess_history ash 
    ON s.snap_id = ash.snap_id
    AND s.dbid = ash.dbid
    AND s.instance_number = ash.instance_number
WHERE s.begin_interval_time >= SYSDATE - 7
GROUP BY s.snap_id, s.begin_interval_time, s.end_interval_time
ORDER BY s.begin_interval_time DESC;
```

### Historical Trend Analysis

```sql
-- Historical wait event trends
SELECT 
    TRUNC(sample_time) as activity_date,
    wait_class,
    COUNT(*) as samples,
    ROUND(COUNT(*) * 100 / SUM(COUNT(*)) OVER (PARTITION BY TRUNC(sample_time)), 2) as daily_pct
FROM dba_hist_active_sess_history
WHERE sample_time >= SYSDATE - 30
AND wait_class IS NOT NULL
GROUP BY TRUNC(sample_time), wait_class
ORDER BY activity_date DESC, samples DESC;
```

## Performance Tuning with ASH

### Identifying Performance Bottlenecks

#### Step 1: Overall System Analysis

```sql
-- System-wide bottleneck identification
SELECT 
    wait_class,
    COUNT(*) as samples,
    ROUND(COUNT(*) * 100 / SUM(COUNT(*)) OVER (), 2) as pct_total,
    COUNT(DISTINCT session_id) as affected_sessions
FROM v$active_session_history
WHERE sample_time >= SYSDATE - 1/24
GROUP BY wait_class
ORDER BY samples DESC;
```

#### Step 2: Drill Down to Specific Issues

```sql
-- Drill down to specific wait events
SELECT 
    event,
    COUNT(*) as samples,
    ROUND(AVG(wait_time)/1000, 2) as avg_wait_ms,
    COUNT(DISTINCT sql_id) as unique_sqls,
    COUNT(DISTINCT session_id) as unique_sessions
FROM v$active_session_history
WHERE sample_time >= SYSDATE - 1/24
AND wait_class = '&wait_class'  -- From step 1 results
GROUP BY event
ORDER BY samples DESC;
```

#### Step 3: Root Cause Analysis

```sql
-- Root cause analysis for specific event
SELECT 
    ash.sql_id,
    s.sql_text,
    ash.current_obj#,
    o.object_name,
    COUNT(*) as samples,
    ash.p1text,
    ash.p1,
    ash.p2text,
    ash.p2
FROM v$active_session_history ash
LEFT JOIN v$sql s ON ash.sql_id = s.sql_id
LEFT JOIN dba_objects o ON ash.current_obj# = o.object_id
WHERE ash.sample_time >= SYSDATE - 1/24
AND ash.event = '&specific_event'  -- From step 2
GROUP BY ash.sql_id, s.sql_text, ash.current_obj#, o.object_name,
         ash.p1text, ash.p1, ash.p2text, ash.p2
ORDER BY samples DESC;
```

### SQL Tuning with ASH

#### Identify Problematic SQL Plans

```sql
-- Compare different execution plans for same SQL
SELECT 
    sql_id,
    sql_plan_hash_value,
    COUNT(*) as samples,
    ROUND(AVG(wait_time)/1000, 2) as avg_wait_ms,
    COUNT(CASE WHEN event IS NULL THEN 1 END) as cpu_samples,
    COUNT(CASE WHEN wait_class = 'User I/O' THEN 1 END) as io_samples
FROM v$active_session_history
WHERE sample_time >= SYSDATE - 7
AND sql_id = '&sql_id'
GROUP BY sql_id, sql_plan_hash_value
ORDER BY samples DESC;
```

#### Analyze SQL Execution Patterns

```sql
-- SQL execution pattern analysis
WITH sql_executions AS (
    SELECT 
        sql_id,
        sql_exec_id,
        MIN(sample_time) as start_time,
        MAX(sample_time) as end_time,
        COUNT(*) as duration_samples,
        COUNT(CASE WHEN event IS NULL THEN 1 END) as cpu_samples,
        COUNT(CASE WHEN wait_class = 'User I/O' THEN 1 END) as io_samples
    FROM v$active_session_history
    WHERE sample_time >= SYSDATE - 1
    AND sql_id = '&sql_id'
    AND sql_exec_id IS NOT NULL
    GROUP BY sql_id, sql_exec_id
)
SELECT 
    sql_id,
    COUNT(*) as total_executions,
    ROUND(AVG(duration_samples), 2) as avg_duration_seconds,
    ROUND(MIN(duration_samples), 2) as min_duration_seconds,
    ROUND(MAX(duration_samples), 2) as max_duration_seconds,
    ROUND(AVG(cpu_samples), 2) as avg_cpu_seconds,
    ROUND(AVG(io_samples), 2) as avg_io_seconds
FROM sql_executions
GROUP BY sql_id;
```

## ASH Reporting

### Creating Custom ASH Reports

#### Daily ASH Summary Report

```sql
-- Daily ASH summary report procedure
– Daily ASH summary report procedure
CREATE OR REPLACE PROCEDURE generate_daily_ash_report(
p_report_date DATE DEFAULT TRUNC(SYSDATE-1)
) AS
v_report_date DATE := TRUNC(p_report_date);
v_total_samples NUMBER;
BEGIN
– Get total samples for the day
SELECT COUNT(*) INTO v_total_samples
FROM dba_hist_active_sess_history
WHERE TRUNC(sample_time) = v_report_date;
DBMS_OUTPUT.PUT_LINE('ASH Daily Report for ' || TO_CHAR(v_report_date, 'YYYY-MM-DD'));
DBMS_OUTPUT.PUT_LINE('=' || RPAD('=', 60, '='));
DBMS_OUTPUT.PUT_LINE('Total ASH Samples: ' || v_total_samples);
-- Top wait events
DBMS_OUTPUT.PUT_LINE(CHR(10) || 'Top Wait Events:');
DBMS_OUTPUT.PUT_LINE('-' || RPAD('-', 60, '-'));
FOR rec IN (
    SELECT 
        wait_class,
        event,
        COUNT(*) as samples,
        ROUND(COUNT(*) * 100 / v_total_samples, 2) as pct
    FROM dba_hist_active_sess_history
    WHERE TRUNC(sample_time) = v_report_date
    AND event IS NOT NULL
    GROUP BY wait_class, event
    ORDER BY samples DESC
    FETCH FIRST 10 ROWS ONLY
) LOOP
    DBMS_OUTPUT.PUT_LINE(RPAD(rec.wait_class, 20) || ' - ' || 
                       RPAD(rec.event, 30) || 
                       ': ' || LPAD(rec.samples, 6) || ' samples (' || 
                       LPAD(rec.pct, 5) || '%)');
END LOOP;
-- Top SQL statements
DBMS_OUTPUT.PUT_LINE(CHR(10) || 'Top SQL Statements:');
DBMS_OUTPUT.PUT_LINE('-' || RPAD('-', 60, '-'));
FOR rec IN (
    SELECT 
        ash.sql_id,
        COUNT(*) as samples,
        ROUND(COUNT(*) * 100 / v_total_samples, 2) as pct,
        NVL(sql.sql_text, 'SQL text not found') as sql_text
    FROM dba_hist_active_sess_history ash
    LEFT JOIN dba_hist_sqltext sql ON ash.sql_id = sql.sql_id
    WHERE TRUNC(ash.sample_time) = v_report_date
    AND ash.sql_id IS NOT NULL
    GROUP BY ash.sql_id, sql.sql_text
    ORDER BY samples DESC
    FETCH FIRST 10 ROWS ONLY
) LOOP
    DBMS_OUTPUT.PUT_LINE('SQL_ID: ' || rec.sql_id || 
                       ' - Samples: ' || rec.samples || 
                       ' (' || rec.pct || '%)');
    DBMS_OUTPUT.PUT_LINE('  ' || SUBSTR(rec.sql_text, 1, 80) || 
                       CASE WHEN LENGTH(rec.sql_text) > 80 THEN '...' ELSE '' END);
    DBMS_OUTPUT.PUT_LINE(' ');
END LOOP;
-- Top sessions by activity
DBMS_OUTPUT.PUT_LINE(CHR(10) || 'Top Sessions by Activity:');
DBMS_OUTPUT.PUT_LINE('-' || RPAD('-', 60, '-'));
FOR rec IN (
    SELECT 
        session_id,
        session_serial#,
        user_id,
        program,
        COUNT(*) as samples,
        ROUND(COUNT(*) * 100 / v_total_samples, 2) as pct
    FROM dba_hist_active_sess_history
    WHERE TRUNC(sample_time) = v_report_date
    GROUP BY session_id, session_serial#, user_id, program
    ORDER BY samples DESC
    FETCH FIRST 10 ROWS ONLY
) LOOP
    DBMS_OUTPUT.PUT_LINE('SID: ' || rec.session_id || 
                       ', Serial#: ' || rec.session_serial# ||
                       ', User: ' || rec.user_id ||
                       ' - ' || rec.samples || ' samples (' || rec.pct || '%)');
    DBMS_OUTPUT.PUT_LINE('  Program: ' || NVL(rec.program, 'Unknown'));
    DBMS_OUTPUT.PUT_LINE(' ');
END LOOP;
-- CPU vs Wait time breakdown
DBMS_OUTPUT.PUT_LINE(CHR(10) || 'CPU vs Wait Time Breakdown:');
DBMS_OUTPUT.PUT_LINE('-' || RPAD('-', 60, '-'));
FOR rec IN (
    SELECT 
        CASE 
            WHEN session_state = 'ON CPU' THEN 'CPU'
            ELSE 'WAITING'
        END as activity_type,
        COUNT(*) as samples,
        ROUND(COUNT(*) * 100 / v_total_samples, 2) as pct
    FROM dba_hist_active_sess_history
    WHERE TRUNC(sample_time) = v_report_date
    GROUP BY 
        CASE 
            WHEN session_state = 'ON CPU' THEN 'CPU'
            ELSE 'WAITING'
        END
    ORDER BY samples DESC
) LOOP
    DBMS_OUTPUT.PUT_LINE(RPAD(rec.activity_type, 15) || 
                       ': ' || LPAD(rec.samples, 8) || 
                       ' samples (' || LPAD(rec.pct, 6) || '%)');
END LOOP;
-- Hourly activity distribution
DBMS_OUTPUT.PUT_LINE(CHR(10) || 'Hourly Activity Distribution:');
DBMS_OUTPUT.PUT_LINE('-' || RPAD('-', 60, '-'));
FOR rec IN (
    SELECT 
        TO_CHAR(sample_time, 'HH24') as hour,
        COUNT(*) as samples,
        ROUND(COUNT(*) * 100 / v_total_samples, 2) as pct
    FROM dba_hist_active_sess_history
    WHERE TRUNC(sample_time) = v_report_date
    GROUP BY TO_CHAR(sample_time, 'HH24')
    ORDER BY hour
) LOOP
    DBMS_OUTPUT.PUT_LINE('Hour ' || rec.hour || ':00' ||
                       ' - ' || LPAD(rec.samples, 6) || 
                       ' samples (' || LPAD(rec.pct, 5) || '%)');
END LOOP;
-- Top wait classes summary
DBMS_OUTPUT.PUT_LINE(CHR(10) || 'Wait Class Summary:');
DBMS_OUTPUT.PUT_LINE('-' || RPAD('-', 60, '-'));
FOR rec IN (
    SELECT 
        NVL(wait_class, 'CPU') as wait_class,
        COUNT(*) as samples,
        ROUND(COUNT(*) * 100 / v_total_samples, 2) as pct
    FROM dba_hist_active_sess_history
    WHERE TRUNC(sample_time) = v_report_date
    GROUP BY wait_class
    ORDER BY samples DESC
) LOOP
    DBMS_OUTPUT.PUT_LINE(RPAD(rec.wait_class, 20) || 
                       ': ' || LPAD(rec.samples, 8) || 
                       ' samples (' || LPAD(rec.pct, 6) || '%)');
END LOOP;
DBMS_OUTPUT.PUT_LINE(CHR(10) || '=' || RPAD('=', 60, '='));
DBMS_OUTPUT.PUT_LINE('Report completed at: ' || TO_CHAR(SYSDATE, 'YYYY-MM-DD HH24:MI:SS'));
EXCEPTION
WHEN OTHERS THEN
DBMS_OUTPUT.PUT_LINE(’Error generating ASH report: ’ || SQLERRM);
RAISE;
END generate_daily_ash_report;
/
```
