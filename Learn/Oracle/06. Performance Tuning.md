## Chapter 1: Selectivity and Cardinality

Performance tuning is one area where most Junior DBAs face those tough-to-break problems. The kind of problems which require deep understanding of the concepts before you can even point what is going wrong in the system. We will be going through the basics knowledge in the Performance Tuning area in series of posts.

### Selectivity

**Definition**: It represents the fraction of rows filtered by an operation, so you can say it is a measure of uniqueness.

#### Key Characteristics:
- **Range**: Its value is between 0 and 1
- **Calculation**: selectivity = (rows returned after filter) / (total rows before filter)

#### Examples:

**Example 1 - Good Selectivity:**
- Query returned 100 rows initially
- After applying filter (WHERE condition), final result is 10 rows
- Selectivity = 10/100 = 0.1 (or 10%)
- This is **GOOD selectivity** because the filter significantly reduced the result set

**Example 2 - Bad Selectivity:**
- Query returned 200 rows initially  
- After applying filter, final result is still 200 rows
- Selectivity = 200/200 = 1.0 (or 100%)
- This is **BAD selectivity** because the filter didn't reduce the result set at all

#### Selectivity Classifications:

**GOOD Selectivity:**
- A column is highly selective if a SQL returns a small number of duplicate rows
- Means the filter is effective at narrowing down results
- Results in better performance

**BAD Selectivity:**
- A column is least selective if a SQL returns all or large number of rows
- Means the filter is not effective
- Results in poor performance

#### Important Notes:
- When you run `SELECT * FROM EMP` without any filters, selectivity will be automatically 1 as all rows will be returned
- **Adding a composite Index** is the best way to make BAD selectivity become GOOD selectivity
- Using more than one column makes the Index more unique which improves Index selectivity

### Cardinality

**Definition**: The number of rows returned by an operation is the cardinality.

#### Relationship Formula:
```
cardinality = selectivity × number of input rows
```

#### Practical Example:
- Query initially retrieved 200 records from database
- After applying filters, final number of rows is 50
- **Selectivity** = 50/200 = 0.25 (25%)
- **Cardinality** = 50 (or 200 × 0.25 = 50)

#### Impact on Performance:
Sometimes the Oracle optimizer is not able to predict the number of rows that a given operator will return due to reasons like:
- Missing table statistics
- Outdated statistics
- Complex predicates

This can prevent Oracle from estimating the cost of a query plan correctly, which can lead to:
- Selection of suboptimal execution plans
- Cardinality estimation errors
- Slow running queries

### Detailed Examples

#### Example 1: Query Without Filter
```sql
SELECT MAX(EMP_NUMBER) FROM EMP;
```
**Scenario**: Table EMP has 10 records total

**Analysis**:
- **Selectivity** = number of rows accessed / total number of rows = 10/10 = 1.0
- **Interpretation**: 100% of the rows were accessed
- **Cardinality** = number of rows accessed = 10

#### Example 2: Query With Filter  
```sql
SELECT MAX(EMP_NUMBER) FROM EMP WHERE LAST_NAME = 'SMITH';
```
**Scenario**: Only 4 employees have LAST_NAME as 'SMITH' out of 10 total records

**Analysis**:
- **Selectivity** = number of rows accessed / total number of rows = 4/10 = 0.4
- **Interpretation**: 40% of the rows were accessed
- **Cardinality** = number of rows accessed = 4

This demonstrates how adding a selective filter condition improves selectivity from 1.0 to 0.4, making the query more efficient.

---

## Chapter 2: Parsing

From performance tuning perspectives, it is very important to understand the concept of parsing. Parsing is the primary phase in SQL execution, followed by other stages: Execute and Fetch.

### Parsing Basics

Whenever a SQL statement is executed, the Oracle Engine performs the following actions:

1. **Validate the Syntax** - Check if the SQL statement is syntactically correct
2. **Validate the Objects** - Verify that all objects referenced in the statement exist
3. **Check Privileges** - Ensure the user has necessary privileges to execute the statement
4. **Search Shared Pool** - Verify if the statement is already available in the shared pool by:
   - Oracle engine calculates the hash value for the SQL statement
   - Looks in the shared pool for matching hash
5. **Allocate Memory** - If statement is not present, allocate shared memory and create a cursor in shared pool
6. **Generate Execution Plan** - Create the optimal execution plan for the statement

### Types of Parses

#### Hard Parse

**Definition**: A hard parse occurs when the statement is not available in shared memory or this is a brand new statement that the user is trying to execute.

**When Hard Parse Occurs**:
- Statement has never been executed before
- Statement was aged out of shared pool due to memory pressure
- Statement text doesn't exactly match existing statements (even case sensitivity matters)

**Process**: All parsing steps (1-6 above) need to be completed

**Impact**: 
- Requires extra system resources
- CPU-intensive operation
- Also known as **'Library Cache Miss'**

#### Soft Parse

**Definition**: A soft parse occurs when the statement was executed earlier, was already parsed, and is available in memory.

**Process**: Oracle only needs to perform steps 1-3 (syntax validation, object validation, privilege check) since the remaining tasks were already completed earlier.

**Benefits**:
- Much faster than hard parse
- Minimal resource consumption
- Also known as **'Library Cache Hit'**
- Follows the principle: "work hard once and reap benefits multiple times"

### Why Hard Parses Should Be Avoided

There are two key reasons why hard parses should be kept to the bare minimum required:

#### 1. CPU Intensive Operations
- **Generation of an execution plan is a very CPU-intensive operation**
- Each hard parse consumes significant CPU resources
- High hard parse rates can lead to CPU bottlenecks

#### 2. Memory Serialization Issues
- **Memory in the shared pool is limited**
- **Memory operations are serialized** - they must happen one at a time
- Memory operations use **shared pool latches** and **library cache latches**
- When many hard parses happen simultaneously:
  - Other processes must wait in queue to get the shared pool latch
  - This creates contention and reduces overall system performance
  - Impacts both shared pool latch and library cache latch availability

### Performance Implications

#### Hard Parse Impact:
- High CPU consumption
- Memory contention
- Increased response times
- Reduced throughput
- Latch waits

#### Soft Parse Benefits:
- Low CPU consumption  
- Reduced memory operations
- Faster response times
- Higher throughput
- Better scalability

### Best Practices

1. **Use Bind Variables** - Promotes statement reuse and soft parsing
2. **Consistent SQL Text** - Ensure identical statements have identical text (case, spacing, etc.)
3. **Adequate Shared Pool Size** - Prevent aging out of frequently used statements
4. **Monitor Parse Ratios** - Track hard vs soft parse ratios
5. **Application Design** - Design applications to reuse SQL statements

### Monitoring Parsing

Key metrics to monitor:
- Hard parse rate
- Soft parse rate  
- Parse time CPU vs total CPU
- Library cache hit ratio
- Shared pool latch contention

---

## Chapter 3: Parent and Child Cursors

### What is a Cursor?

A "cursor" is a memory area in the library cache that is allocated to the SQL statement which users execute. This memory area stores key information about the SQL statement like SQL text, SQL execution plan, statistics etc.

### Why Two Kinds of Cursors?

This is by Oracle database design that you have two kinds of cursors: Parent and Child. For each SQL statement that you execute, Oracle engine will generate two cursors: parent and child cursor. Two cursors are generated because for the same SQL statement, there could be other differences like there can be different bind values or two different schema or different literals values, etc. The parent Cursor will hold the SQL statement and the child cursor will hold the information related to the differences. This essentially makes child cursor as deciding factor as to SQL statement will go for hard or soft parse.

### Parent Cursor

- It stores the SQL text of the cursor. When two statements are identical word-by-word, they will share the same parent Cursor.
- Every parent cursor would execute with at least one child cursor created for it.
- Parent cursors are represented in the view **V$SQLAREA**. VERSION_COUNT column in the v$sqlarea can tell us how many child cursors does this parent cursor have.

### Child Cursor

- Each parent has at least one child cursor and can have more than 1 child cursors also
- While parent cursor stores the SQL Text, the child cursor stores other important information related to SQL statement like:
  - Environment details
  - Statistics details
  - Bind Variables details
  - Execution Plan details
  - Bind Variables details
- Child Cursor takes less memory space as SQL Text is not stored in child cursor
- Every child cursor must belong to a parent
- Child cursor decides whether a query will undergo a hard parse or a soft parse. You may find situation that SQL query is same for two statements so Parent cursors are same but the child cursor is not shareable to SQL goes for hard parse (re-compile).
- Child cursors are represented in the view **V$SQL**
- **V$SQL_SHARED_CURSOR** is very useful view as it provides the reasons why the optimizer decided mark the cursor as un-shared. So anytime you see that SQL statement was same and still hard parse happened, look at this view.

### V$SQL_SHARED_CURSOR View

This view explains why a particular child cursor is not shared with existing child cursors which caused more than one child cursor to be created for same Parent cursor. Each column in this view identifies a specific reason why the cursor cannot be shared. The columns describe the various reasons with "Y" or "N" for the value. You should focus on the column which has value as 'Y'. A specific child may have failed sharing for several reasons – ie: a different reason for trying to use different existing child cursors.

### CURSOR_SHARING Database Parameter

Since we are discussing parent and child cursors, it is very important that we discuss a bit about the cursor_sharing database parameter. CURSOR_SHARING determines what kind of SQL statements can share the same cursors.

cursor_sharing database parameters can have three different values:

#### EXACT
Only allows statements with identical text to share the same cursor.

#### FORCE
Forces statements that may differ in some literals, but are otherwise identical, to share a cursor, unless the literals affect the meaning of the statement.

#### SIMILAR
Causes statements that may differ in some literals, but are otherwise identical, to share a cursor, unless the literals affect either the meaning of the statement or the degree to which the plan is optimized.

### Examples of Different SQL Statements

The default cursor_sharing criteria is EXACT which means that each different SQL statement a new parent cursor is created. Example, below are two different SQL statements:

```sql
select * from EMP WHERE EMP_ID=1;
select * from EMP where EMP_ID=1;
```

These are two different SQLs although both will produce same result. "where" is written in capital letter in first statement while in the second statement it is written in small letters.

Even below two statements are two different SQLs:

```sql
select * from EMP where EMP_ID=1;
select * from EMP where EMP_ID=2;
```

These are different SQLs as literal values (1 and 2) are different. Executing above will create two Parent cursors if cursor_sharing parameter is EXACT.

Whereas, if you put cursor_sharing criteria is FORCE or SIMILAR, executing above two SQLs will generate single Parent cursor. When we do this, Oracle strips out all the literals from the query and replaces them with bind variables in the optimization phase. Please keep in mind that making cursor_sharing is not always an advantage. It can prove bad for SQL performance also as we will discuss in further posts.

---

## Chapter 4: Bind Variables

### Introduction to Bind Variables

Bind variables are often known as one of the key feature for better SQL query performance. Bind variables as per Oracle documentation is a placeholder in a SQL statement that must be replaced with a valid value or value address for the statement to execute successfully. By using bind variables, you can write a SQL statement that accepts inputs or parameters at run time.

You can think of SQL query as a kind of "function" in any programming language and bind variables as "values" that you pass to the function.

### Example

```sql
-- Without bind variable (using literal)
Select * from EMP where EMP_ID=1;

-- With bind variable
Select * from EMP where EMP_ID=:a;
```

First statement uses a literal value (1) to run the query while the second SQL statement uses bind variable (:a) to run the SQL statement. The value of (:a) will be provide to Oracle at run time.

### Key Benefits of Bind Variables

Having bind variable defined in the SQL query instead of literal values (which can be different every time) will make sure that Oracle will create only one Parent Cursor for the SQL statement. Oracle look for exact text match for the SQL statement to see if it is already present in the shared pool and having a bind variable instead of literal value will save a costly hard parse every time same SQL is executed.

Bind variables are specially important in OLTP kind of environments as using bind variables enables soft parsing, which means that less processing time is spent on choosing an optimized execution plan.

### Creating Bind Variables in SQL*Plus

You create bind variables in SQL*Plus with the VARIABLE command. Example:

```sql
VARIABLE mybindVariable VARCHAR2(10)
```

### Advantages of Using Bind Variables

1. **Better Shared Pool Utilization**: Oracle Shared Pool has to hold only one statement rather than a potentially very high number.

2. **No Hard Parsing so Better Performance**: No hard parsing required for SQL statements that only differ in the values.

3. **Reduced "library cache" latch contention**: Bind variables helps in avoiding performance problems due to library cache latch contention which happens every time a hard parse is required.

### Disadvantages of Using Bind Variables

Now coming to disadvantages of using bind variables. Note that in many cases bind variables will prove excellent for improving the performance of the database but at time it may produce negative results. Bind variables can reduce the information to calculate optimal access path for (Cost Based Optimizer) CBO.

---
# Chapter 5 Oracle Database Tuning: Comprehensive Notes on Trace and TKPROF

## Table of Contents
1. [Overview](#overview)
2. [Prerequisites and Key Parameters](#prerequisites-and-key-parameters)
3. [Part 1: Trace Generation Methods](#part-1-trace-generation-methods)
4. [Part 2: Generating TKPROF from Trace Files](#part-2-generating-tkprof-from-trace-files)
5. [Part 3: Analyzing TKPROF Files](#part-3-analyzing-tkprof-files)
6. [Oracle EBS Specific Tracing](#oracle-ebs-specific-tracing)
7. [Best Practices and Additional Tips](#best-practices-and-additional-tips)

---

## Overview

### What is Oracle Trace?
**Trace** is an Oracle feature that generates a raw text file containing internal SQL activity when a program is executed. It provides detailed statistics for performance analysis and troubleshooting.

**Key Information Captured:**
- Parse, execute, and fetch counts
- CPU and elapsed times
- Physical reads and logical reads
- Number of rows processed
- Library cache misses
- Username under each parse occurred
- Commit and rollback operations
- Wait events (when enabled)

### What is TKPROF?
**TKPROF** reformats raw trace data into a readable format for performance analysis. It doesn't control trace contents but makes analysis easier.

**Two Essential Goals:**
1. Identify SQL/Operations taking the highest time
2. Identify SQL/Operations consuming the highest resources

---

## Prerequisites and Key Parameters

### Essential Database Parameters

```sql
-- Enable timing statistics
ALTER SYSTEM SET TIMED_STATISTICS = TRUE;

-- Allow unlimited trace file size
ALTER SYSTEM SET MAX_DUMP_FILE_SIZE = UNLIMITED;

-- Comprehensive statistics collection
ALTER SYSTEM SET STATISTICS_LEVEL = ALL;
```

**Parameter Details:**
- **TIMED_STATISTICS**: Must be TRUE for meaningful timing data
- **MAX_DUMP_FILE_SIZE**: Prevents truncated trace files
- **STATISTICS_LEVEL**: ALL provides most comprehensive information

### Trace Levels Overview

| Level | Description | Use Case |
|-------|-------------|----------|
| 1 | Standard SQL Trace | Basic tracing |
| 4 | Includes Bind Variables | When bind values needed |
| 8 | **With Waits (Recommended)** | **Default choice - shows wait events** |
| 12 | Binds + Waits | Comprehensive but overhead-heavy |
| 16 | STAT lines for each execution | Equivalent to plan_stat=ALL_EXECUTIONS |
| 32 | Never write STAT lines | Equivalent to plan_stat=NEVER |
| 64 | STAT lines every minute | Adaptive statistics (11.2.0.2 only) |

**Best Practice:** Use Level 8 (with waits) by default. Only use Level 12 when bind variable values are specifically needed.

---

## Part 1: Trace Generation Methods

### 1. Session-Level Tracing

#### Basic SQL_TRACE
```sql
-- Enable trace for current session
ALTER SESSION SET SQL_TRACE = TRUE;

-- Disable trace
ALTER SESSION SET SQL_TRACE = FALSE;

-- 11g+ Event Syntax
ALTER SESSION SET EVENTS 'sql_trace bind=true';
ALTER SESSION SET EVENTS 'sql_trace bind=true, wait=true';
```

#### 10046 Event Tracing (Recommended)
```sql
-- Level 1 (Basic)
ALTER SESSION SET EVENTS '10046 trace name context forever';

-- Level 8 (With Waits - Recommended)
ALTER SESSION SET EVENTS '10046 trace name context forever, level 8';

-- Level 12 (Binds and Waits)
ALTER SESSION SET EVENTS '10046 trace name context forever, level 12';

-- Disable tracing
ALTER SESSION SET EVENTS '10046 trace name context off';
```

### 2. SQL_ID Specific Tracing (11g+)
```sql
-- Single SQL_ID
ALTER SYSTEM SET EVENTS 'sql_trace [sql: sql_id=4k1jlmn567cr7] bind=true, wait=true';

-- Multiple SQL_IDs
ALTER SYSTEM SET EVENTS 'sql_trace [sql: sql_id=5t6ygtsa3d356|6fa43fgg0rrtp] bind=true, wait=true';
```

### 3. Database-Level Tracing
```sql
-- System-wide (Use with caution!)
ALTER SYSTEM SET SQL_TRACE = TRUE;
ALTER SYSTEM SET EVENTS '10046 trace name context forever, level 8';

-- Disable system-wide
ALTER SYSTEM SET SQL_TRACE = FALSE;
ALTER SYSTEM SET EVENTS '10046 trace name context off';
```

**Warning:** System-wide tracing creates significant overhead. Use only for short periods in controlled environments.

### 4. DBMS_MONITOR Package

#### Session Tracing
```sql
-- Enable for specific session
EXEC DBMS_MONITOR.SESSION_TRACE_ENABLE(
  session_id => &SESSION_ID, 
  serial_num => &SERIAL_NUM, 
  waits => TRUE, 
  binds => FALSE
);

-- Disable for specific session
EXEC DBMS_MONITOR.SESSION_TRACE_DISABLE(
  session_id => &SESSION_ID, 
  serial_num => &SERIAL_NUM
);
```

#### Client ID Tracing
```sql
-- Enable for client identifier
EXEC DBMS_MONITOR.CLIENT_ID_TRACE_ENABLE(
  client_id => 'client_identifier',
  waits => TRUE,
  binds => FALSE
);

-- Disable
EXEC DBMS_MONITOR.CLIENT_ID_TRACE_DISABLE(
  client_id => 'client_identifier'
);
```

### 5. DBMS_SESSION Package
```sql
-- Find session details
SELECT sid, serial#, username, program 
FROM v$session 
WHERE username = 'TARGET_USER';

-- Enable tracing
EXEC DBMS_SESSION.SET_SQL_TRACE_IN_SESSION(&SID, &SERIAL#, TRUE);

-- Disable tracing
EXEC DBMS_SESSION.SET_SQL_TRACE_IN_SESSION(&SID, &SERIAL#, FALSE);
```

### 6. ORADEBUG Utility

**Steps:**
1. **Find Process Information:**
```sql
SELECT p.PID, p.SPID, s.SID 
FROM v$process p, v$session s 
WHERE s.paddr = p.addr 
AND s.sid = &SESSION_ID;
```

2. **Apply Trace:**
```sql
CONNECT / AS SYSDBA
ORADEBUG SETOSPID &SPID
ORADEBUG UNLIMIT
ORADEBUG EVENT 10046 TRACE NAME CONTEXT FOREVER, LEVEL 8
```

3. **Disable Trace:**
```sql
ORADEBUG EVENT 10046 TRACE NAME CONTEXT OFF
```

### 7. User-Level Tracing with Triggers
```sql
CREATE OR REPLACE TRIGGER SYS.set_trace 
AFTER LOGON ON DATABASE 
WHEN (USER like '&USERNAME') 
DECLARE 
  lcommand varchar(200); 
BEGIN 
  EXECUTE IMMEDIATE 'ALTER SESSION SET TRACEFILE_IDENTIFIER=''From_Trigger'''; 
  EXECUTE IMMEDIATE 'ALTER SESSION SET STATISTICS_LEVEL=ALL'; 
  EXECUTE IMMEDIATE 'ALTER SESSION SET MAX_DUMP_FILE_SIZE=UNLIMITED'; 
  EXECUTE IMMEDIATE 'ALTER SESSION SET EVENTS ''10046 trace name context forever, level 8'''; 
END set_trace;
/
```

### 8. AUTOTRACE in SQL*Plus
```sql
-- Show execution plan only
SET AUTOTRACE TRACEONLY EXPLAIN

-- Show statistics only
SET AUTOTRACE TRACEONLY STATISTICS

-- Show both
SET AUTOTRACE TRACEONLY

-- Show results + plan + statistics
SET AUTOTRACE ON
```

---

## Trace File Locations and Naming

### File Locations

**Pre-11g:**
- User sessions: `user_dump_dest`
- Background processes: `background_dump_dest`

**11g and Later:**
```sql
-- Find trace directory
SELECT value FROM V$DIAG_INFO WHERE NAME = 'Diag Trace';
```
Location: `<diagnostic_dest>/diag/rdbms/<dbname>/<instname>/trace`

### File Naming Convention
Format: `<instance>_ora_<ospid>_<identifier>.trc`

**Components:**
- `<instance>`: Database instance name
- `<ospid>`: OS Process ID from v$process.spid
- `<identifier>`: Trace file identifier

---

## Part 2: Generating TKPROF from Trace Files

### Basic TKPROF Syntax
```bash
tkprof <input_trace_file> <output_file> [options]
```

### Essential TKPROF Command
```bash
tkprof ora123.trc ora123.out sort=fchela,exeela,prsela sys=no
```

### Key TKPROF Parameters

| Parameter | Description | Example |
|-----------|-------------|---------|
| **sort** | Sort statements by resource usage | `sort=fchela,exeela,prsela` |
| **sys** | Include/exclude SYS recursive SQL | `sys=no` (recommended) |
| **print** | Limit number of statements | `print=10` |
| **explain** | Generate execution plans | `explain=user/pass@db` |
| **table** | Specify plan table | `table=sys.plan_table` |
| **record** | Create replay script | `record=replay.sql` |
| **width** | Control output line width | `width=132` |

### Sort Options (Most Useful)

| Sort Code | Description |
|-----------|-------------|
| **fchela** | Fetch elapsed time |
| **exeela** | Execute elapsed time |
| **prsela** | Parse elapsed time |
| **fchdsk** | Fetch disk reads |
| **exedsk** | Execute disk reads |
| **prsdsk** | Parse disk reads |
| **fchqry** | Fetch buffer gets |
| **exeqry** | Execute buffer gets |
| **prsqry** | Parse buffer gets |

### Common TKPROF Examples

```bash
# Basic sorted output
tkprof trace.trc output.out sort=fchela,exeela,prsela sys=no

# Top 10 resource-intensive statements
tkprof trace.trc output.out sort=exeela,fchela print=10 sys=no

# With execution plans
tkprof trace.trc output.out explain=system/password@orcl sys=no

# Complete analysis with custom table
tkprof trace.trc output.out sort=fchela,exeela explain=system/pass table=my_plan_table sys=no
```

### TKPROF Output Components

**What TKPROF Contains:**
1. **SQL Text** - Executed statements
2. **Timing Information** - Parse/Execute/Fetch times
3. **Resource Usage** - CPU, disk reads, buffer gets
4. **Wait Information** - Wait events (if trace level 8+)
5. **Execution Plans** - Runtime execution paths
6. **Row Counts** - Actual rows processed

---

## Part 3: Analyzing TKPROF Files

### TKPROF File Structure

#### 1. Header Section
- TKPROF version and generation time
- Source trace file name
- Sort options used
- Column definitions

#### 2. Body Section (Main Analysis Area)
Each SQL statement contains:
- SQL text
- Parse/Execute/Fetch statistics
- Library cache information
- Row source execution plan
- Wait events (if available)

#### 3. Summary Section
- Overall statistics
- Recursive vs non-recursive SQL
- Library cache hit ratios
- Total elapsed time

### Understanding Body Section Metrics

#### Performance Metrics Table

| Metric | Unit | Description |
|--------|------|-------------|
| **count** | Number | Times parsed, executed, or fetched |
| **cpu** | Seconds | CPU time consumed |
| **elapsed** | Seconds | Total elapsed time |
| **disk** | Blocks | Physical reads from disk |
| **query** | Blocks | Logical reads (consistent mode) |
| **current** | Blocks | Logical reads (current mode) |
| **rows** | Number | Rows processed |

#### Call Types Explained

| Call Type | Description | When It Occurs |
|-----------|-------------|----------------|
| **Parse** | SQL parsing and optimization | First time SQL is seen |
| **Execute** | Statement execution | Every execution |
| **Fetch** | Row retrieval | SELECT statements only |

### Key Analysis Techniques

#### 1. Identify Performance Issues
```
Look for:
- High elapsed times
- High CPU consumption
- Excessive physical reads (disk)
- High parse counts
- Poor fetch patterns
```

#### 2. Parse Analysis
```
Hard Parse Indicators:
- Misses in library cache during parse = 1
- High parse times
- Parse count close to execute count

Soft Parse (Good):
- Misses in library cache during parse = 0
- Low parse times
- Parse count << execute count
```

#### 3. I/O Analysis
```
Physical vs Logical Reads:
- High disk reads = I/O bound
- High query/current = Memory intensive
- Buffer Cache Hit Ratio = 1 - (disk/(query+current))

Target: >95% hit ratio in most cases
```

#### 4. Row Source Operations
```sql
-- Example execution plan output
Rows (1st) Rows (avg) Rows (max)  Row Source Operation
---------- ---------- ----------  -------------------
         1          1          1  UPDATE CUSTOMERS (cr=4 pr=0 pw=0 time=0 us)
         1          1          1   INDEX UNIQUE SCAN CUSTOMERS_PK (cr=3 pr=0 pw=0 time=0 us)
```

**Row Source Metrics:**
- **cr**: Consistent reads (query mode)
- **pr**: Physical reads
- **pw**: Physical writes
- **time**: Time in microseconds

### Summary Section Analysis

#### Library Cache Hit Ratio Calculation
```
Physical reads = sum(disk)
Logical reads = sum(query + current)
Hit Ratio = 1 - (Physical Reads / Logical Reads)

Target: > 95% for most applications
```

#### Key Summary Metrics
- **Parse efficiency**: Total parses vs total SQL statements
- **Fetch efficiency**: Fetches vs rows returned
- **Overall elapsed time**: Total time for all operations

### Wait Events Analysis (Level 8+ Traces)

| Wait Event | Meaning | Action |
|------------|---------|--------|
| **db file sequential read** | Single block reads | Check index usage, disk I/O |
| **db file scattered read** | Multi-block reads | Full table scans |
| **latch: shared pool** | Library cache contention | Reduce hard parsing |
| **enq: TX - row lock contention** | Row locking issues | Application logic review |

---

## Oracle EBS Specific Tracing

### 1. Forms-Level Tracing

**Steps:**
1. Set profile: `Utilities:Diagnostics = Yes`
2. Navigate to target form
3. Help → Diagnostics → Trace → Trace with Waits
4. Select "Unlimited Trace File Size"
5. Execute required actions
6. Help → Diagnostics → Trace → No Trace

### 2. Self-Service/OAF Tracing

**Steps:**
1. Set profile: `FND: Diagnostics = Yes`
2. Navigate to HTML application
3. Click Diagnostics icon → Set Trace Level → Trace with Waits
4. Execute required actions
5. Diagnostics icon → Set Trace Level → Disable Trace

### 3. Concurrent Program Tracing

#### Request Level (R12+ only)
1. Set profile: `Concurrent: Allow Debugging = Yes`
2. Submit Request → Debug Options
3. Enable "SQL Trace" → "SQL Trace with Waits"
4. Submit request

#### Program Level
1. Navigate to Concurrent → Program → Define
2. Query target program
3. Check "Enable Trace" checkbox
4. Submit requests will be traced

### 4. Profile Option Method
Set `Initialization SQL Statement – Custom` profile:
```sql
BEGIN 
  FND_CTL.FND_SESS_CTL(','
    ,'TRUE'
    ,'TRUE'
    ,''
    ,'ALTER SESSION SET TRACEFILE_IDENTIFIER="custom_trace" 
      STATISTICS_LEVEL=ALL 
      MAX_DUMP_FILE_SIZE=unlimited 
      EVENTS="10046 TRACE NAME CONTEXT FOREVER, LEVEL 8"'
  );
END;
```

---

## Best Practices and Additional Tips

### 1. Trace Management
```bash
# Monitor trace directory size
du -sh $ORACLE_BASE/diag/rdbms/*/trace

# Clean up old traces
find $TRACE_DIR -name "*.trc" -mtime +7 -delete

# Compress large traces
gzip large_trace.trc
```

### 2. TRCSESS Utility (10g+)
Consolidate multiple trace files:
```bash
trcsess output=consolidated.trc session=123 *.trc
trcsess output=client_trace.trc clientid=BATCH_USER *.trc
```

### 3. Performance Analysis Workflow

1. **Enable appropriate trace level**
2. **Execute problematic operation**  
3. **Generate TKPROF with proper sorting**
4. **Analyze in order:**
   - Summary section (overall impact)
   - Top resource-consuming SQLs
   - Parse efficiency
   - Wait events
   - Execution plans

### 4. Common Issues and Solutions

| Issue | Symptom | Solution |
|-------|---------|----------|
| **Over-parsing** | Parse count ≈ Execute count | Use bind variables |
| **Full table scans** | High "disk" reads | Add/modify indexes |
| **Inefficient joins** | High row counts in plans | Review join order |
| **Lock contention** | High TX wait events | Review transaction logic |

### 5. Additional Analysis Tools

#### SQL Performance Scripts
```sql
-- Find expensive SQL by elapsed time
SELECT sql_id, elapsed_time, executions, 
       elapsed_time/executions avg_elapsed
FROM v$sql 
WHERE executions > 0
ORDER BY elapsed_time DESC;

-- Check current sessions with tracing
SELECT s.sid, s.serial#, s.username, s.program,
       p.tracefile
FROM v$session s, v$process p
WHERE s.paddr = p.addr
AND s.sql_trace = 'enabled';
```

#### Monitoring Queries
```sql
-- Find trace files by session
SELECT s.sid, s.serial#, s.username,
       p.spid, p.tracefile
FROM v$session s, v$process p  
WHERE s.paddr = p.addr
AND s.sid = &SESSION_ID;

-- Check enabled traces
SELECT trace_type, primary_id, qualifier_id1, 
       waits, binds 
FROM dba_enabled_traces;
```

### 6. Advanced Techniques

#### Custom TKPROF Analysis
```bash
# Create custom analysis script
tkprof input.trc output.out sort=fchela,exeela,prsela sys=no | \
grep -E "(elapsed|CPU|disk)" > performance_summary.txt

# Extract only top SQLs
tkprof input.trc output.out print=5 sort=exeela sys=no
```

#### Automated Analysis
```sql
-- PL/SQL block for automated trace analysis
DECLARE
  v_tracefile VARCHAR2(500);
  v_sql VARCHAR2(1000);
BEGIN
  SELECT p.tracefile INTO v_tracefile
  FROM v$session s, v$process p
  WHERE s.paddr = p.addr
  AND s.sid = SYS_CONTEXT('userenv','sid');
  
  DBMS_OUTPUT.PUT_LINE('Trace file: ' || v_tracefile);
  
  -- Enable tracing
  EXECUTE IMMEDIATE 'ALTER SESSION SET EVENTS ''10046 trace name context forever, level 8''';
  
  -- Your SQL operations here
  
  -- Disable tracing  
  EXECUTE IMMEDIATE 'ALTER SESSION SET EVENTS ''10046 trace name context off''';
END;
/
```

### 7. Security and Considerations

- **Sensitive Data**: Level 12 traces contain bind variables (potential sensitive data)
- **File System Impact**: Large traces can fill disk space
- **Performance Overhead**: Tracing adds 5-10% overhead
- **Production Use**: Always coordinate with stakeholders
- **Cleanup**: Establish trace file retention policies

### 8. Troubleshooting Common Issues

| Problem | Possible Cause | Solution |
|---------|----------------|----------|
| **No trace file generated** | Wrong parameters/permissions | Check diagnostic_dest, permissions |
| **Empty TKPROF** | Trace disabled prematurely | Verify trace duration |
| **Missing wait events** | Trace level < 8 | Use level 8 or 12 |
| **Huge trace files** | Long-running operations | Use print parameter, monitor size |

---

## Summary

Oracle trace and TKPROF are powerful tools for database performance analysis. Key takeaways:

1. **Use Level 8 tracing** (with waits) for most scenarios
2. **Sort TKPROF output** by elapsed time for efficiency
3. **Focus on high-impact SQLs** first
4. **Analyze parse efficiency** to identify optimization opportunities
5. **Monitor wait events** to understand bottlenecks
6. **Clean up trace files** regularly to prevent space issues

The combination of proper tracing methodology and systematic TKPROF analysis provides deep insights into database performance issues and guides effective optimization strategies.
